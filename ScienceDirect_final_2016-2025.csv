Item type,Authors,Title,Journal,Publication year,DOI,URLs,Volume,Issue,Pages,Date published,ISSN,Abstract,Keywords,Notes
Journal Article,"Chen S,Jiang W",Feature selection-based web application defect prediction: a systematic review,International Journal of Web Information Systems,2024,10.1108/IJWIS-05-2025-0132,http://dx.doi.org/10.1108/IJWIS-05-2025-0132;https://www.sciencedirect.com/science/article/pii/S1744008424000077,21,4,545-561,2024,1744-0084,"Purpose This survey focuses on software defect prediction (SDP) in web applications, systematically analyzing recent advances in feature selection-based SDP methodologies. It aims to investigate the impact of different feature selection techniques, including filter, wrapper, embedding and hybrid methods, on prediction performance while summarizing current research trends and challenges. Design/methodology/approach To systematically analyze and summarize this research question, the authors collected relevant papers published between 2020 and 2024 from academic databases including Google Scholar, DBLP, ACM Digital Library, Springer Link, Web of Science and IEEE Xplore, using keywords such as Web application defect prediction (WADP), SDP, feature selection and software fault prediction. Findings This literature review, based on 40 core studies carefully selected from IEEE Xplore, Science Direct, ACM Digital Library and Springer Link, provides profound and valuable insights into the critical role of feature selection methods in WADP. Originality/value This study explores key research questions and highlights the popularity trends and notable advantages of filter, wrapper, embedding and hybrid methods. These findings lay a solid foundation for a comprehensive understanding of the current trends in feature – selection methods and establish a strong groundwork for future research aimed at enhancing the accuracy and efficiency of Web application defect – prediction models.","Deep learning, Machine learning, Feature selection, Web information systems, Defect prediction",
Journal Article,"Sivavelu S,Palanisamy V",Nonparametric Statistical Feature Scaling Based Quadratic Regressive Convolution Deep Neural Network for Software Fault Prediction,"Computers, Materials and Continua",2024,10.32604/cmc.2024.047407,http://dx.doi.org/10.32604/cmc.2024.047407;https://www.sciencedirect.com/science/article/pii/S1546221824003217,78,3,3469-3487,2024,1546-2218,"The development of defect prediction plays a significant role in improving software quality. Such predictions are used to identify defective modules before the testing and to minimize the time and cost. The software with defects negatively impacts operational costs and finally affects customer satisfaction. Numerous approaches exist to predict software defects. However, the timely and accurate software bugs are the major challenging issues. To improve the timely and accurate software defect prediction, a novel technique called Nonparametric Statistical feature scaled QuAdratic regressive convolution Deep nEural Network (SQADEN) is introduced. The proposed SQADEN technique mainly includes two major processes namely metric or feature selection and classification. First, the SQADEN uses the nonparametric statistical Torgerson–Gower scaling technique for identifying the relevant software metrics by measuring the similarity using the dice coefficient. The feature selection process is used to minimize the time complexity of software fault prediction. With the selected metrics, software fault perdition with the help of the Quadratic Censored regressive convolution deep neural network-based classification. The deep learning classifier analyzes the training and testing samples using the contingency correlation coefficient. The softstep activation function is used to provide the final fault prediction results. To minimize the error, the Nelder–Mead method is applied to solve non-linear least-squares problems. Finally, accurate classification results with a minimum error are obtained at the output layer. Experimental evaluation is carried out with different quantitative metrics such as accuracy, precision, recall, F-measure, and time complexity. The analyzed results demonstrate the superior performance of our proposed SQADEN technique with maximum accuracy, sensitivity and specificity by 3%, 3%, 2% and 3% and minimum time and space by 13% and 15% when compared with the two state-of-the-art methods.","Software defect prediction, feature selection, nonparametric statistical Torgerson–Gower scaling technique, quadratic censored regressive convolution deep neural network, softstep activation function, nelder–mead method",
Journal Article,"Nevendra M,Singh P",TRGNet: a deep transfer learning approach for software defect prediction,Expert Systems with Applications,2025,10.1016/j.eswa.2025.127799,http://dx.doi.org/10.1016/j.eswa.2025.127799;https://www.sciencedirect.com/science/article/pii/S0957417425014216,282,,127799,2025,0957-4174,"Software defect prediction (SDP) aims to automatically locate defective modules to find bugs and prioritise testing efforts. Researchers are now shifting into semantic features in order to develop predictive models for accurate prediction by using deep learning. But the source code conversion into the semantic feature fails to capture the essential features and correlation. This often degrades the performance of the prediction model. However, well-known authors have already shown the importance of software module metrics for software defect prediction. To take the advantage of software metrics via deep transfer learning in this paper, software module metrics are transformed into images. We proposed the TRGNet model, which extracts transferable features from source projects using pre-trained GoogLeNet and consolidates with a meta-estimator to minimize the divergence in sample distributions between projects. In this model, we feed the transformed image file of software modules to train it for within-project defect prediction (WPDP) and cross-project defect prediction (CPDP). The experimental results with AlexNet, ResNet, SqueezeNet, and other state-of-the-art models indicate that the proposed TRGNet model significantly improves the state-of-the-art defect prediction task by 13.31 % in WPDP and 16.88 % in CPDP scenarios. Moreover, the computational cost analysis reveals that TRGNet significantly reduces memory utilization while maintaining competitive training and inference times compared to other deep learning models, making it a highly efficient and scalable approach for SDP.","Deep transfer learning, GoogLeNet, Cross project defect prediction, Defect prediction, With-in project defect prediction",
Journal Article,"Zain ZM,Sakri S,Asmak Ismail NH,Parizi RM",Software Defect Prediction Harnessing on Multi 1-Dimensional Convolutional Neural Network Structure,"Computers, Materials and Continua",2021,10.32604/cmc.2022.022085,http://dx.doi.org/10.32604/cmc.2022.022085;https://www.sciencedirect.com/science/article/pii/S1546221821000989,71,1,1521-1546,2021,1546-2218,"Developing successful software with no defects is one of the main goals of software projects. In order to provide a software project with the anticipated software quality, the prediction of software defects plays a vital role. Machine learning, and particularly deep learning, have been advocated for predicting software defects, however both suffer from inadequate accuracy, overfitting, and complicated structure. In this paper, we aim to address such issues in predicting software defects. We propose a novel structure of 1-Dimensional Convolutional Neural Network (1D-CNN), a deep learning architecture to extract useful knowledge, identifying and modelling the knowledge in the data sequence, reduce overfitting, and finally, predict whether the units of code are defects prone. We design large-scale empirical studies to reveal the proposed model's effectiveness by comparing four established traditional machine learning baseline models and four state-of-the-art baselines in software defect prediction based on the NASA datasets. The experimental results demonstrate that in terms of f-measure, an optimal and modest 1D-CNN with a dropout layer outperforms baseline and state-of-the-art models by 66.79% and 23.88%, respectively, in ways that minimize overfitting and improving prediction performance for software defects. According to the results, 1D-CNN seems to be successful in predicting software defects and may be applied and adopted for a practical problem in software engineering. This, in turn, could lead to saving software development resources and producing more reliable software.","Defects, software defect prediction, deep learning, convolutional neural network, machine learning",
Journal Article,"Dong X,Liang Y,Miyamoto S,Yamaguchi S",Ensemble learning based software defect prediction,Journal of Engineering Research,2023,10.1016/j.jer.2023.10.038,http://dx.doi.org/10.1016/j.jer.2023.10.038;https://www.sciencedirect.com/science/article/pii/S2307187723002997,11,4,377-391,2023,2307-1877,"Currently, the cost to detect and solve software defects is a heavy burden on software projects. So, it is significant to predict software defects at the earlier stages of the software development lifecycle. In this study, seven commonly-used machine learning and deep learning algorithms were studied and the performance of defect classification on 4 representative public datasets from NASA and the PROMISE repository was demonstrated. Furthermore, three classical ensemble learning methods (Bagging, Boosting, and Stacking) were used to improve the prediction performance. Six metrics, including accuracy, precision, f1-score, recall, the area under the receiver operating characteristic curve (AUC), and G-Mean were utilized to evaluate the performance. It was noted that ensemble learning exceeded all the other seven algorithms. Ensemble learning achieved the highest AUC of 0.99, the highest G-Mean of 0.96, and an average F1-score of 0.97. Under a time-sensitive scenario, the Boosting method was a good choice as it spent less runtime and had a similar performance to the other two ensemble learning methods in most cases.","Software defect prediction, MLP, CNN, Ensemble learning",
Journal Article,"Mishra A,Sharma A",Deep learning based continuous integration and continuous delivery software defect prediction with effective optimization strategy,Knowledge-Based Systems,2024,10.1016/j.knosys.2024.111835,http://dx.doi.org/10.1016/j.knosys.2024.111835;https://www.sciencedirect.com/science/article/pii/S0950705124004696,296,,111835,2024,0950-7051,"Software defect prediction is one of the most difficult tasks in the IT sector. Continuous Integration and Continuous Delivery (CI/CD) software defect prediction is used in earlier stage, which consumes less amount of time. Various learning algorithms, such as convolutional neural networks and other machine learning algorithms (ML), are employed to forecast the flaws in the software model. In these existing algorithms, some issues are noticed, such as high computational complexity, excessive time consumption, the need for more energy to predict the model and a high-loss function. To address these issues, a novel deep learning (DL)-based CI/CD software defect prediction technique applying an effective optimization strategy is provided to improve the model's efficiency. The numerical data are collected from open source, and the obtained data is initially labeled based on time domain limitations. Initially, the Modified Synthetic Minority Over-Sampling Technique (M-SMOTE) mechanism is applied to balance the data to avoid overfitting problems, and data normalization is performed to rescale and normalize the data properly. After moralization, the optimal set of features is extracted from the data using Focal Bidirectional Encoder Representations from Transformers (F-BERT) to enhance the efficiency of the model. Finally, the software defects are predicted using Bidirectional Long Short-Term Memory (Bi-LSTM) integrated into the convolutional Gated recurrent units (GRU) model (Bi-CGRU) based on collected features. Hybrid Levy Rao (HLR) optimization is used to tune the hyperparameters properly in the classifier model. The proposed model's performance indicators are examined. The proposed model has a 95.32 % accuracy, a 93.3 % recall, a 94.98 % Matthews correlation coefficient, and an F1-score of 91.355 %. The proposed model generates less labeling noise and wait time than existing methods.","Gated recurrent units, Synthetic minority oversampling technique, Bidirectional encoder representations from transformers, Levy flight distribution, Rao optimization and bidirectional long short-term memory",
Journal Article,"Zain ZM,Sakri S,Ismail NH",Application of Deep Learning in Software Defect Prediction: Systematic Literature Review and Meta-analysis,Information and Software Technology,2023,10.1016/j.infsof.2023.107175,http://dx.doi.org/10.1016/j.infsof.2023.107175;https://www.sciencedirect.com/science/article/pii/S0950584923000290,158,,107175,2023,0950-5849,"Context Despite recent attention given to Software Defect Prediction (SDP), the lack of any systematic effort to assess existing empirical evidence on the application of Deep Learning (DL) in SDP indicates that it is still relatively under-researched. Objective To synthesize literature on SDP using DL, pertaining to measurements, models, techniques, datasets, and achievements; to obtain a full understanding of current SDP-related methodologies using DL; and to compare the DL models’ performances with those of Machine Learning (ML) models in classifying software defects. Method We completed a thorough review of the literature in this domain. To answer the research issues, results from primary investigations were synthesized. The preliminary findings for DL vs. ML in SDP were verified by using meta-analysis (MA). Result We discovered 63 primary studies that passed the systematic literature review quality evaluation. However, only 19 primary studies passed the MA quality evaluation. The five most popular performance measurements employed in SDP were f-measure, recall, accuracy, precision, and Area Under the Curve (AUC). The top five DL techniques used in building SDP models were Convolutional Neural Network (CNN), Deep Neural Network (DNN), Long Short-Term Memory (LSTM), Deep Belief Network (DBN), and Stacked Denoising Autoencoder (SDAE). PROMISE and NASA datasets were found to be used more frequently to train and test DL models in SDP. The MA results show that DL was favored over ML in terms of study and dataset across accuracy, f-measure, and AUC. Conclusion The application of DL in SDP remains a challenge, but it has the potential to achieve better predictive performance when the performance-influencing parameters are optimized. We provide a reference point for future research which could be used to improve research quality in this domain.","Deep Learning, Software Defect Prediction, Systematic Literature Review, Meta-Analysis",
Journal Article,"Han J,Huang C,Liu J",bjCnet: A contrastive learning-based framework for software defect prediction,Computers & Security,2024,10.1016/j.cose.2024.104024,http://dx.doi.org/10.1016/j.cose.2024.104024;https://www.sciencedirect.com/science/article/pii/S0167404824003298,145,,104024,2024,0167-4048,"Defect prediction based on deep learning is proposed to provide practitioners with reliable and practical tools to determine whether an area of code is defective. Compared with traditional code features, semantic features of source codes automatically extracted by neural networks can better reflect the semantic differences between codes. However, the small difference between some bug codes and clean codes poses a challenge for deep learning models in distinguishing them, leading to a low accuracy in defect prediction. In this paper, we propose bjCnet, a software defect prediction framework based on contrastive learning. It fine-tunes the pre-trained Transformer-based code large language model via a supervised contrastive learning network, achieving accurate defect prediction. We evaluate the prediction effect of bjCnet, the results demonstrate that the highest accuracy and f1-score achieved by bjCnet are both 0.948, surpassing the performance of the state-of-the-art approaches selected for comparison.","Deep learning, Defect prediction, Transformer, Large language model, Contrastive learning",
Journal Article,"Tong H,Liu B,Wang S",Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning,Information and Software Technology,2018,10.1016/j.infsof.2017.11.008,http://dx.doi.org/10.1016/j.infsof.2017.11.008;https://www.sciencedirect.com/science/article/pii/S0950584917300113,96,,94-111,2018,0950-5849,"Context Software defect prediction (SDP) plays an important role in allocating testing resources reasonably, reducing testing costs, and ensuring software quality. However, software metrics used for SDP are almost entirely traditional features compared with deep representations (DPs) from deep learning. Although stacked denoising autoencoders (SDAEs) are powerful for feature learning and have been successfully applied in other fields, to the best of our knowledge, it has not been investigated in the field of SDP. Meanwhile, class-imbalance is still a pressing problem needing to be addressed. Objective In this paper, we propose a novel SDP approach, SDAEsTSE, which takes advantages of SDAEs and ensemble learning, namely the proposed two-stage ensemble (TSE). Method Our method mainly includes two phases: the deep learning phase and two-stage ensemble (TSE) phase. We first use SDAEs to extract the DPs from the traditional software metrics, and then a novel ensemble learning approach, TSE, is proposed to address the class-imbalance problem. Results Experiments are performed on 12 NASA datasets to demonstrate the effectiveness of DPs, the proposed TSE, and SDAEsTSE, respectively. The performance is evaluated in terms of F-measure, the area under the curve (AUC), and Matthews correlation coefficient (MCC). Generally, DPs, TSE, and SDAEsTSE contribute to significantly higher performance compared with corresponding traditional metrics, classic ensemble methods, and benchmark SDP models. Conclusions It can be concluded that (1) deep representations are promising for SDP compared with traditional software metrics, (2) TSE is more effective for addressing the class-imbalance problem in SDP compared with classic ensemble learning methods, and (3) the proposed SDAEsTSE is significantly effective for SDP.","Software defect prediction, Stacked denoising autoencoders, Ensemble learning, Software metrics, Deep learning",
Journal Article,"Malhotra R,Singh P",DHG-BiGRU: Dual-attention based hierarchical gated BiGRU for software defect prediction,Information and Software Technology,2025,10.1016/j.infsof.2024.107646,http://dx.doi.org/10.1016/j.infsof.2024.107646;https://www.sciencedirect.com/science/article/pii/S0950584924002519,179,,107646,2025,0950-5849,"Context: Software defect prediction (SDP) is a prominent research area focussed on anticipating defects early in the software lifecycle. Traditional machine learning models are based on static features, which are not enough to capture contextual information in the source code. In recent years, researchers have also developed deep learning models that extract semantic information from source code using the abstract syntax tree (AST). These approaches often combine static and semantic features by a simple merger operation. Objective: The article aims to address the limitations of the existing models by utilizing advanced feature extraction and integration techniques. It develops a deep learning model that can effectively prioritize the crucial features and intelligently combine the static and semantic features to provide robust predictions Method: The article proposes a novel model namely, dual-attention-based hierarchical gated BiGRU (DHG-BiGRU). The model first employs a static feature extractor (StatFE) and a semantic feature extractor (SemFE) to capture static and semantic features, respectively. Next, the outputs from StatFE and SemFE are passed to individual BiGRUs. The BiGRU output associated with the semantic features is subsequently processed by a dual attention mechanism (DAM), that captures the complex semantic information with emphasis on the most crucial features. Afterward, the hierarchical gated fusion (HGF) meticulously merges the static and semantic features. Finally, these integrated features are passed through a sigmoid function to predict defects. Results: The extensive experiments on extensively utilized datasets from the PROMISE repository reveal that DHG-BiGRU performs significantly better than the most advanced models and consistently achieves higher precision, recall and f-measure, demonstrating a reliable prediction capability. Conclusion: The results of the study underscore the potential advanced feature extraction and integration techniques for SDP. By achieving considerable improvements over state-of-the-art techniques, the proposed approach paves the way for sophisticated defect prediction models to improve software quality and reliability.","Software defect prediction, Software quality, Abstract syntax tree, Bidirectional gated recurrent unit, Deep semantic learning, Natural language processing",
Journal Article,"Zhang N,Ying S,Ding W,Zhu K,Zhu D",WGNCS: A robust hybrid cross-version defect model via multi-objective optimization and deep enhanced feature representation,Information Sciences,2021,10.1016/j.ins.2021.05.008,http://dx.doi.org/10.1016/j.ins.2021.05.008;https://www.sciencedirect.com/science/article/pii/S0020025521004540,570,,545-576,2021,0020-0255,"For a constantly-evolving software project with multiple releasing versions, Cross-Version Defect Prediction (CVDP) can identify the potential defect in the latter one by mining historical defect information from the prior releasing software versions. Unfortunately, the imbalanced class distribution and the complex intrinsic structure in software projects make it challenging to obtain suitable defect features and construct a predominant CVDP model. To address these challenges, we propose a robust hybrid CVDP model named WGNCS based on WGAN-GP (Wasserstein GAN with Gradient Penalty), multi-objective NSGA-III (Non-dominated Sorting Genetic Algorithm - III) algorithm and hybrid CNN-SVM (Convolutional Neural Network – Support Vector Machine) in this study, which has three main merits: (1) employ a powerful deep learning generative model – WGAN-GP to conduct data augmentation tasks, thereby achieving defect class balance and generating more training instances. (2) utilize the multi-objective NSGA-III algorithm to select the fewest representative training feature subset for the minimum error. (3) construct a single powerful defect predictor CNN-SVM by cascading a high-level deep semantic feature extractor (CNN) and a classifier (SVM) with the fixed non-linear Gaussian kernel function. We verify the CVDP performance of WGNCS on 32 cross-version pairs derived from 45 software project versions. The experimental results demonstrate that the WGNCS model can exhibit encouraging performance.","Cross-version defect prediction, Multi-objective feature selection, Deep learning techniques, Wasserstein GAN with Gradient Penalty, Convolutional neural network",
Journal Article,"Xing Y,Qian X,Guan Y,Yang B,Zhang Y",Cross-project defect prediction based on G-LSTM model,Pattern Recognition Letters,2022,10.1016/j.patrec.2022.04.039,http://dx.doi.org/10.1016/j.patrec.2022.04.039;https://www.sciencedirect.com/science/article/pii/S0167865522001519,160,,50-57,2022,0167-8655,"Cross-project defect prediction (CPDP) is currently a hot research direction in the field of software reliability. Traditional CPDP methods cannot capture the semantic and contextual information of programs by handcrafted features, which affects the prediction performance. In this paper, we apply technology in the NLP domain to solve it. We first extract token vectors from the abstract syntax tree (AST) of source and target code files, and then convert them into numerical vectors by the word embedding algorithm of continuous bag-of-word model (CBOW) as the input of the proposed deep learning model named Generative Adversarial Long-Short Term Memory Neural Networks (G-LSTM). The model integrates generative adversarial network (GAN) and bidirectional long-short term memory networks (BiLSTM) with attention mechanism to automatically learn semantic and contextual features of programs. Specifically, GAN is used to eliminate the differences in data distribution between source and target projects, and BiLSTM is the feature extraction encoder. We compose five projects of the PROMISE dataset into 20 source-target project pairs and conduct comparison experiments on them. The experimental results demonstrate that our method outperforms some traditional and state-of-the-art CPDP methods in terms of the evaluation metrics of AUC and Acc.","Computational language processing, Cross-project defect prediction, Long-term and short-term memory neural network, Continuous bag-of-word model, Generative adversarial network",
Journal Article,"Briciu A,Czibula G,Lupea M",A study on the relevance of semantic features extracted using BERT-based language models for enhancing the performance of software defect classifiers,Procedia Computer Science,2023,10.1016/j.procs.2023.10.149,http://dx.doi.org/10.1016/j.procs.2023.10.149;https://www.sciencedirect.com/science/article/pii/S1877050923013078,225,,1601-1610,2023,1877-0509,"In the context of new research in the software defect prediction (SDP) task using pre-trained language models, the present study aims to analyze the relevance of semantic features extracted using BERT-based language models for the detection of defective source codes. RoBERTa and CodeBERT-MLM language models are used to generate source code embeddings that capture semantic and contextual features which help in solving language understanding tasks such as SDP. The learned representations are then fed to a neural network-based SDP classifier in order to decide which of the learned code embeddings are more informative in discriminating between faulty and non-faulty software entities. Extensive experiments are conducted in a cross-version SDP scenario for Apache Calcite, an open-source framework for data management. The evaluation results of the defect classifiers show a statistically significant improvement when the code representations are learned by the pre-trained models compared with the semantic representations provided by other natural language-based models, doc2vec and LSI.","software defects prediction, deep learning, code embedding, pre-trained language model, RoBERTa, CodeBERT, Calcite software 2000 MSC: 68T07, 68T10",27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)
Journal Article,"Shi K,Lu Y,Chang J,Wei Z",PathPair2Vec: An AST path pair-based code representation method for defect prediction,Journal of Computer Languages,2020,10.1016/j.cola.2020.100979,http://dx.doi.org/10.1016/j.cola.2020.100979;https://www.sciencedirect.com/science/article/pii/S2590118420300393,59,,100979,2020,2590-1184,"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code.","Defect prediction, AST path, Deep learning, Representation learning",
Journal Article,"Long W,Qixin Z,Zakharov MA,Lee S",Optimizing fault prediction in software based on MnasNet/LSTM optimized by an improved lotus flower algorithm,Egyptian Informatics Journal,2025,10.1016/j.eij.2025.100623,http://dx.doi.org/10.1016/j.eij.2025.100623;https://www.sciencedirect.com/science/article/pii/S1110866525000167,29,,100623,2025,1110-8665,"Software quality and reliability are very important problems in the field of software production. Software error and defect detection technology is one of the most important research goals in the field of software system reliability that prevents software failure. Therefore, the performance of the defect prediction model in order to accurately predict defects is important in improving and effectiveness of models. In this paper, an attempt has been made to present a hybrid and efficient classification model based on deep learning and metaheuristic models for predicting defects of software. The basis of the suggested model is utilizing a combination of MnasNet (for extracting the semantics of AST tokens) and LSTM (for keeping the key features). It has been improved with the help of an improved variant of Lotus Flower Algorithm (ILFA) so that appropriate coefficients and acceptable results can be produced with the optimization power of metaheuristic algorithms and the learning power of the network. For evaluating the results of the suggested model, the model is applied to a practical dataset and the results are compared with some different methods. The new combined model worked best for the Xerces project, reaching 93% accuracy, which was much better than other models. It also performed well on different projects, improving accuracy by 3.3% to 7.9% after cleaning the data and fixing the issue of uneven class sizes. The results indicate that the proposed model can achieve the highest values ​​of efficiency.","Faults, Defect, Prediction, MnasNet, Long short-term memory, Improved Lotus Flower Algorithm",
Journal Article,"Mehta S,Kumar L,Misra S,Patnaik KS,Singh V",Nested deep learning with learned network embeddings for software defect prediction,Applied Soft Computing,2025,10.1016/j.asoc.2025.113057,http://dx.doi.org/10.1016/j.asoc.2025.113057;https://www.sciencedirect.com/science/article/pii/S1568494625003680,174,,113057,2025,1568-4946,"Existing software (SW) defect prediction approaches and the models are majorly based on features extracted from the code of the software to build defect datasets for predictive modeling. However, these models fail to sufficiently capture the complex, latent dependencies within the software components, which acts as a hindrance in achieving higher predictive accuracy. This study introduces an improved defect prediction model, the Nested Deep Learning (NDL) model, that leverages network embeddings from call graphs for enhanced representation of intricate hierarchical class dependencies and interactions. This work evaluates six network-embedding algorithms by applying them to call graphs of 10 real software projects, generating embeddings of dimensions 32 and 128. A total of 50 NDL models—with and without dropout layers—are developed, and a comparative evaluation of these models is conducted against traditional classifier-based models. This evaluation demonstrated the superiority of the NDL model with dropout, achieving a mean AUC of 0.87, an 8.98 % improvement over the traditional classifier-based models. Among the evaluated embedding methods, LINE embeddings outperformed others, and integrating network embeddings with software metrics led to a 15.85 % AUC improvement over using software metrics alone. The optimal configuration—combining software metrics with LINE embeddings (dimension 128) in an NDL model with three deep learning layers and dropout—achieved a mean AUC of 0.93, surpassing all other configurations by 3.33–14.81 %. This study is the first to validate the effectiveness of a nested deep learning framework for modeling call graph dependencies through network embeddings, providing a scalable and robust approach for improving software defect prediction.","Software defect prediction, Nested deep learning, Network embedding, Deep neural network, Call graph",
Journal Article,"Zhou T,Sun X,Xia X,Li B,Chen X",Improving defect prediction with deep forest,Information and Software Technology,2019,10.1016/j.infsof.2019.07.003,http://dx.doi.org/10.1016/j.infsof.2019.07.003;https://www.sciencedirect.com/science/article/pii/S0950584919301466,114,,204-216,2019,0950-5849,"Context Software defect prediction is important to ensure the quality of software. Nowadays, many supervised learning techniques have been applied to identify defective instances (e.g., methods, classes, and modules). Objective However, the performance of these supervised learning techniques are still far from satisfactory, and it will be important to design more advanced techniques to improve the performance of defect prediction models. Method We propose a new deep forest model to build the defect prediction model (DPDF). This model can identify more important defect features by using a new cascade strategy, which transforms random forest classifiers into a layer-by-layer structure. This design takes full advantage of ensemble learning and deep learning. Results We evaluate our approach on 25 open source projects from four public datasets (i.e., NASA, PROMISE, AEEEM and Relink). Experimental results show that our approach increases AUC value by 5% compared with the best traditional machine learning algorithms. Conclusion The deep strategy in DPDF is effective for software defect prediction.","Software defect prediction, Deep forest, Cascade strategy, Empirical evaluation",
Journal Article,"Fei Q,Hu H,Yin G,Sun Z",A Software Defect Prediction Method Using a Multivariate Heterogeneous Hybrid Deep Learning Algorithm,"Computers, Materials and Continua",2025,10.32604/cmc.2024.058931,http://dx.doi.org/10.32604/cmc.2024.058931;https://www.sciencedirect.com/science/article/pii/S1546221825000724,82,2,3251-3279,2025,1546-2218,"Software defect prediction plays a critical role in software development and quality assurance processes. Effective defect prediction enables testers to accurately prioritize testing efforts and enhance defect detection efficiency. Additionally, this technology provides developers with a means to quickly identify errors, thereby improving software robustness and overall quality. However, current research in software defect prediction often faces challenges, such as relying on a single data source or failing to adequately account for the characteristics of multiple coexisting data sources. This approach may overlook the differences and potential value of various data sources, affecting the accuracy and generalization performance of prediction results. To address this issue, this study proposes a multivariate heterogeneous hybrid deep learning algorithm for defect prediction (DP-MHHDL). Initially, Abstract Syntax Tree (AST), Code Dependency Network (CDN), and code static quality metrics are extracted from source code files and used as inputs to ensure data diversity. Subsequently, for the three types of heterogeneous data, the study employs a graph convolutional network optimization model based on adjacency and spatial topologies, a Convolutional Neural Network-Bidirectional Long Short-Term Memory (CNN-BiLSTM) hybrid neural network model, and a TabNet model to extract data features. These features are then concatenated and processed through a fully connected neural network for defect prediction. Finally, the proposed framework is evaluated using ten promise defect repository projects, and performance is assessed with three metrics: F1, Area under the curve (AUC), and Matthews correlation coefficient (MCC). The experimental results demonstrate that the proposed algorithm outperforms existing methods, offering a novel solution for software defect prediction.","Software defect prediction, multiple heterogeneous data, graph convolutional network models based on adjacency and spatial topologies, CNN-BiLSTM, TabNet",
Journal Article,"Zhang F,Che Y,Liang T,Jiang W",Clone consistent-defect prediction based on deep learning method,Information Sciences,2023,10.1016/j.ins.2023.03.007,http://dx.doi.org/10.1016/j.ins.2023.03.007;https://www.sciencedirect.com/science/article/pii/S0020025523003031,633,,357-369,2023,0020-0255,"Many consistent changes take place across code clones in software, and this has emerged as a severe issue for software security. If the developers forget to modify the relevant clones consistently, such modifications will introduce consistent-defect. Researchers leverage machine learning techniques to predict clone consistent-defect by representing these changes with the designed attributes. Meanwhile, deep learning technology has demonstrated tremendous potential in characterizing source code. As such, we explore whether deep learning technology can enhance the effectiveness of clone consistent-defect prediction. In this study, we investigate various neural networks for modeling clone consistent change. Specifically, our approach models code clones and their evolution to capture the semantic properties automatically from the perspectives of clone fragment, clone group, and clone evolution, as opposed to manually generated attributes. To evaluate the effectiveness of our approach, we conduct an experiment on the dataset collected from 8 open-source projects. The results demonstrate that our neural network models are efficient both in cross-project and within-project scenarios, with F-measures of around 80% and recalls of around 90%. We conclude that deep learning technology may successfully assist developers in predicting clone consistent-defect, so helping to improve the security of code clones by alerting developers to confirm their consistency.","Clone consistent change, Consistent-defect, Software maintenance, Software safety, Deep learning",
Journal Article,"He H,Xu H,Zhao G,Huang G,Zhao B",Towards structured semantic representation via hierarchical transformer network for software defect prediction,Journal of Systems and Software,2026,10.1016/j.jss.2025.112672,http://dx.doi.org/10.1016/j.jss.2025.112672;https://www.sciencedirect.com/science/article/pii/S0164121225003413,232,,112672,2026,0164-1212,"In recent years, deep learning techniques have gained widespread adoption in source code defect prediction. Nevertheless, significant challenges persist in effectively capturing and representing the structural characteristics inherent in programming code. Primary limitations include: (i) text sequence-based models frequently inadequately represent the distinctive structural properties of source code, and (ii) approaches dependent on compiler-generated structural representations exhibit substantial toolchain dependencies. This makes them difficult to apply to languages lacking mature compilers or to non-standard code samples. This paper addresses these challenges by systematically analyzing the fundamental differences between source code and natural language text. We propose a compiler-independent hierarchical representation method for source code. Additionally, we introduce an adaptive, layered defect prediction model named Hierarchical Transformer Network, which learns structured contextual semantic information for function-level defect detection. Experimental results on two widely used real-world datasets, CWE and CodeXGLUE, show that our method outperforms baseline models. Specifically, we observe improvements of 5.11 % and 8.58 % in AUC-ROC, respectively. Compared to the standard Transformer model, our method significantly reduces the computational resources required. The unique two-dimensional hierarchical structure enables the model to capture longer contexts with fewer resources. This approach greatly lowers the computational and learning costs for both model usage and research.","Defect prediction, Structured representation, Attention mechanism, Transformer",
Journal Article,"Chen X,Xia H,Pei W,Ni C,Liu K",Boosting multi-objective just-in-time software defect prediction by fusing expert metrics and semantic metrics,Journal of Systems and Software,2023,10.1016/j.jss.2023.111853,http://dx.doi.org/10.1016/j.jss.2023.111853;https://www.sciencedirect.com/science/article/pii/S0164121223002480,206,,111853,2023,0164-1212,"Just-in-time software defect prediction (JIT-SDP) aims to predict whether a code commit is defect-inducing or defect-clean immediately after developers submit their code commits. In our previous study, we modeled JIT-SDP as a multi-objective optimization problem by designing two potential conflict optimization objectives. By only considering expert metrics for code commits, our proposed multi-objective just-in-time software defect prediction (MOJ-SDP) approach can significantly outperform state-of-the-art supervised and unsupervised baselines. Recent studies have shown that deep learning techniques can be used to automatically extract semantic metrics from code commits and achieved promising performance for JIT-SDP. However, it is unclear how well MOJ-SDP performs when semantic metrics are used, and whether these two types of metrics are complementary and can be boosted by fusing them for MOJ-SDP. We conducted an extensive experiment using 27,319 code commits from 21 real-world open-source projects. Our results show that when using semantic features, the performance of MOJ-SDP can be slightly decreased for Popt, but greatly improved for Recall@20%Effort. However, when these two types of metrics are fused based on the model-level fusion with the maximum rule, the performance can be boosted by a large margin and outperform state-of-the-art JIT-SDP baselines.","Just-in-time defect prediction, Multi-objective optimization, Expert metrics, Semantic metrics, Metric fusion",
Journal Article,"Liu Y,Zhang W,Qin G,Zhao J",A comparative study on the effect of data imbalance on software defect prediction,Procedia Computer Science,2022,10.1016/j.procs.2022.11.349,http://dx.doi.org/10.1016/j.procs.2022.11.349;https://www.sciencedirect.com/science/article/pii/S1877050922020610,214,,1603-1616,2022,1877-0509,"In the current stage, software defect prediction is suffering the imbalanced data problem. Traditional methods are insensitive to defect-prone modules and tend to predict defect-prone modules as defect-free modules. To deal with this problem, sampling techniques are adopted to rebalance the defect-prone and defect-free data to train the predictive model in order to improve the performance. However, it is not clear on the combined effect of the sampling techniques and the machine learning classifiers on the performance of software defect prediction. The intent of the paper is to study the performance impact on defect prediction incurred by different combinations of sampling techniques and machine learning classifiers. Specifically, we investigate three types of sampling techniques as resampling, spread subsampling and SMOTE (Synthetic Minority Over-sampling Technique), and five types of machine learning classifiers as C4.5, naive Bayes, logistic regression, support vector machine and deep learning to study their combined effect on defect prediction. By using the Friedman test and Nemenyi test, we find that there isn't an optimal method among all the 12 combinations in defect prediction. However, support vector machine and deep learning have produced the best performance stably among all the investigated projects. With ANOVA analysis, we find that the sampling techniques have great impact on the outcomes of defect prediction because they produce different data distributions for model training. Nevertheless, the sampling proportion has significant impacts on TPR (True Positive Ratio) and FPR (False Positive Ratio) while it can merely influence the AUC (Area under Curve) and Balance of logistic regression. We explain the experimental results in the paper.","software defect prediction, data imbalance, sampling techniques, machine learning",9th International Conference on Information Technology and Quantitative Management
Journal Article,"Zhao L,Shang Z,Zhao L,Zhang T,Tang YY",Software defect prediction via cost-sensitive Siamese parallel fully-connected neural networks,Neurocomputing,2019,10.1016/j.neucom.2019.03.076,http://dx.doi.org/10.1016/j.neucom.2019.03.076;https://www.sciencedirect.com/science/article/pii/S0925231219305004,352,,64-74,2019,0925-2312,"Software defect prediction (SDP) has caused widespread concern among software engineering researchers, which aims to erect a software defect predictor according to historical data. However, it is still difficult to develop an effective SDP model on high-dimensional and limited data. In this study, a novel SDP model for this problem is proposed, called Siamese parallel fully-connected networks (SPFCNN), which combines the advantages of Siamese networks and deep learning into a unified method. And training this model is administered by AdamW algorithm for finding the best weights. The minimum value of a singular formula is the target of training for SPFCNN model. Significantly, we extensively compared SPFCNN method with the state-of-the-art SDP approaches using six openly available datasets from the NASA repository. Six indexes are used to evaluate the performance of the proposed method. Experimental results showed that the SPFCNN method contributes to significantly higher performance compared with benchmarked SDP approaches, indicating that a cost-sensitive neural network could be developed successfully for SDP.","Siamese parallel fully-connected networks, Cost-sensitive learning, Deep learning, Few-shot learning, Software defect prediction",
Journal Article,"Qiao L,Li X,Umer Q,Guo P",Deep learning based software defect prediction,Neurocomputing,2020,10.1016/j.neucom.2019.11.067,http://dx.doi.org/10.1016/j.neucom.2019.11.067;https://www.sciencedirect.com/science/article/pii/S0925231219316698,385,,100-110,2020,0925-2312,"Software systems have become larger and more complex than ever. Such characteristics make it very challengeable to prevent software defects. Therefore, automatically predicting the number of defects in software modules is necessary and may help developers efficiently to allocate limited resources. Various approaches have been proposed to identify and fix such defects at minimal cost. However, the performance of these approaches require significant improvement. Therefore, in this paper, we propose a novel approach that leverages deep learning techniques to predict the number of defects in software systems. First, we preprocess a publicly available dataset, including log transformation and data normalization. Second, we perform data modeling to prepare the data input for the deep learning model. Third, we pass the modeled data to a specially designed deep neural network-based model to predict the number of defects. We also evaluate the proposed approach on two well-known datasets. The evaluation results illustrate that the proposed approach is accurate and can improve upon the state-of-the-art approaches. On average, the proposed method significantly reduces the mean square error by more than 14% and increases the squared correlation coefficient by more than 8%.","Software defect prediction, Deep learning, Software quality, Software metrics, Robustness evaluation",
Journal Article,"Battulga B,Tsoodol L,Dovdon E,Bold N,Namsrai OE",Metric-based defect prediction from class diagram,Array,2025,10.1016/j.array.2025.100438,http://dx.doi.org/10.1016/j.array.2025.100438;https://www.sciencedirect.com/science/article/pii/S2590005625000657,27,,100438,2025,2590-0056,"A software defect refers to a fault, failure, or error in software. With the rapid development and increasing reliance on software products, it is essential to identify these defects as early and easily as possible, given the efforts and budget invested in their creation and maintenance. In the literature, various approaches such as machine learning (ML) and deep learning (DL), have been proposed and proven effective in detecting defects in source code during the implementation or testing phases of the software development life cycle (SDLC). A promising approach is crucial for predicting defects at earlier stages of the SDLC, particularly during the design phase, with the goal of enhancing software quality while reducing time, effort, and costs. Meanwhile, software metrics provide a quantifiable way to analyze the software, making it easier to identify defects. Many researchers have leveraged these metrics to predict defects using ML and DL methods, achieving state-of-the-art performance. The objective of this paper is to present a novel approach to predict defects in class diagram (i.e., at design stage) using ML and DL with software metrics. Due to a lack of defect datasets extracted from class diagram, firstly, we created a model-based metric dataset using reverse engineering from a code-based dataset. Then, we apply various ML and DL techniques to the newly created dataset to predict defects in classes by classifying them as either defective or clean. The study utilizes a large dataset called the Unified Bug Dataset, which comprises five publicly available sub-datasets. We compare ML and DL models in terms of accuracy, precision, recall, F-measure, AUC and provide a performance comparison against code-based methods. Finally, we conducted a cross-dataset experiment to evaluate the generalizability of our approach.","Software defect prediction, UML Class diagram, Machine learning, Deep learning, Object oriented design metrics, Reverse-engineering, Software quality, Empirical software engineering",
Journal Article,"Zhao Z,Yang B,Li G,Liu H,Jin Z",Precise Learning of Source Code Contextual Semantics via Hierarchical Dependence Structure and Graph Attention Networks,Journal of Systems and Software,2022,10.1016/j.jss.2021.111108,http://dx.doi.org/10.1016/j.jss.2021.111108;https://www.sciencedirect.com/science/article/pii/S0164121221002053,184,,111108,2022,0164-1212,"Deep learning is being used extensively in a variety of software engineering tasks, e.g., program classification and defect prediction. Although the technique eliminates the required process of feature engineering, the construction of source code model significantly affects the performance on those tasks. Most recent works was mainly focused on complementing AST-based source code models by introducing contextual dependencies extracted from CFG. However, all of them pay little attention to the representation of basic blocks, which are the basis of contextual dependencies. In this paper, we integrated AST and CFG and proposed a novel source code model embedded with hierarchical dependencies. Based on that, we also designed a neural network that depends on the graph attention mechanism. Specifically, we introduced the syntactic structural of the basic block, i.e., its corresponding AST, in source code model to provide sufficient information and fill the gap. We have evaluated this model on three practical software engineering tasks and compared it with other state-of-the-art methods. The results show that our model can significantly improve the performance. For example, compared to the best performing baseline, our model reduces the scale of parameters by 50% and achieves 4% improvement on accuracy on program classification task.","Graph neural network, Program analysis, Deep learning, Abstract syntax Tree, Control flow graph",
Journal Article,"Giray G,Bennin KE,Köksal Ö,Babur Ö,Tekinerdogan B",On the use of deep learning in software defect prediction,Journal of Systems and Software,2023,10.1016/j.jss.2022.111537,http://dx.doi.org/10.1016/j.jss.2022.111537;https://www.sciencedirect.com/science/article/pii/S0164121222002138,195,,111537,2023,0164-1212,"Context: Automated software defect prediction (SDP) methods are increasingly applied, often with the use of machine learning (ML) techniques. Yet, the existing ML-based approaches require manually extracted features, which are cumbersome, time consuming and hardly capture the semantic information reported in bug reporting tools. Deep learning (DL) techniques provide practitioners with the opportunities to automatically extract and learn from more complex and high-dimensional data. Objective: The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of the utilization of DL algorithms for SDP in the literature. Method: We systematically selected a pool of 102 peer-reviewed studies and then conducted a quantitative and qualitative analysis using the data extracted from these studies. Results: Main highlights include: (1) most studies applied supervised DL; (2) two third of the studies used metrics as an input to DL algorithms; (3) Convolutional Neural Network is the most frequently used DL algorithm. Conclusion: Based on our findings, we propose to (1) develop more comprehensive DL approaches that automatically capture the needed features; (2) use diverse software artifacts other than source code; (3) adopt data augmentation techniques to tackle the class imbalance problem; (4) publish replication packages.","Software defect prediction, Deep learning, Quality assurance, Systematic literature review",
Journal Article,"Abdu A,Zhai Z,Abdo HA,Algabri R,Lee S",Graph-Based Feature Learning for Cross-Project Software Defect Prediction,"Computers, Materials and Continua",2023,10.32604/cmc.2023.043680,http://dx.doi.org/10.32604/cmc.2023.043680;https://www.sciencedirect.com/science/article/pii/S1546221823000851,77,1,161-180,2023,1546-2218,"Cross-project software defect prediction (CPDP) aims to enhance defect prediction in target projects with limited or no historical data by leveraging information from related source projects. The existing CPDP approaches rely on static metrics or dynamic syntactic features, which have shown limited effectiveness in CPDP due to their inability to capture higher-level system properties, such as complex design patterns, relationships between multiple functions, and dependencies in different software projects, that are important for CPDP. This paper introduces a novel approach, a graph-based feature learning model for CPDP (GB-CPDP), that utilizes NetworkX to extract features and learn representations of program entities from control flow graphs (CFGs) and data dependency graphs (DDGs). These graphs capture the structural and data dependencies within the source code. The proposed approach employs Node2Vec to transform CFGs and DDGs into numerical vectors and leverages Long Short-Term Memory (LSTM) networks to learn predictive models. The process involves graph construction, feature learning through graph embedding and LSTM, and defect prediction. Experimental evaluation using nine open-source Java projects from the PROMISE dataset demonstrates that GB-CPDP outperforms state-of-the-art CPDP methods in terms of F1-measure and Area Under the Curve (AUC). The results showcase the effectiveness of GB-CPDP in improving the performance of cross-project defect prediction.","Cross-project defect prediction, graphs features, deep learning, graph embedding",
Journal Article,"Majd A,Vahidi-Asl M,Khalilian A,Poorsarvi-Tehrani P,Haghighi H",SLDeep: Statement-level software defect prediction using deep-learning model on static code features,Expert Systems with Applications,2020,10.1016/j.eswa.2019.113156,http://dx.doi.org/10.1016/j.eswa.2019.113156;https://www.sciencedirect.com/science/article/pii/S0957417419308735,147,,113156,2020,0957-4174,"Software defect prediction (SDP) seeks to estimate fault-prone areas of the code to focus testing activities on more suspicious portions. Consequently, high-quality software is released with less time and effort. The current SDP techniques however work at coarse-grained units, such as a module or a class, putting some burden on the developers to locate the fault. To address this issue, we propose a new technique called as Statement-Level software defect prediction using Deep-learning model (SLDeep). The significance of SLDeep for intelligent and expert systems is that it demonstrates a novel use of deep-learning models to the solution of a practical problem faced by software developers. To reify our proposal, we defined a suite of 32 statement-level metrics, such as the number of binary and unary operators used in a statement. Then, we applied as learning model, long short-term memory (LSTM). We conducted experiments using 119,989 C/C++ programs within Code4Bench. The programs comprise 2,356,458 lines of code of which 292,064 lines are faulty. The benchmark comprises a diverse set of programs and versions, written by thousands of developers. Therefore, it tends to give a model that can be used for cross-project SDP. In the experiments, our trained model could successfully classify the unseen data (that is, fault-proneness of new statements) with average performance measures 0.979, 0.570, and 0.702 in terms of recall, precision, and accuracy, respectively. These experimental results suggest that SLDeep is effective for statement-level SDP. The impact of this work is twofold. Working at statement-level further alleviates developer's burden in pinpointing the fault locations. Second, cross-project feature of SLDeep helps defect prediction research become more industrially-viable.","Defect, Software fault proneness, Machine learning, Fault prediction model, Software metric",
Journal Article,"Batool I,Khan TA","Software fault prediction using data mining, machine learning and deep learning techniques: A systematic literature review",Computers and Electrical Engineering,2022,10.1016/j.compeleceng.2022.107886,http://dx.doi.org/10.1016/j.compeleceng.2022.107886;https://www.sciencedirect.com/science/article/pii/S0045790622001744,100,,107886,2022,0045-7906,"Software fault/defect prediction assists software developers to identify faulty constructs, such as modules or classes, early in the software development life cycle. There are data mining, machine learning, and deep learning techniques used for software fault prediction. We perform analysis of previously published reviews, surveys, and related studies to distill a list of questions. These questions were either answered in the past but needed a fresh look or they were not considered at all. We justify why answers to newly added questions are important and divide previous work based on data mining, machine learning, and deep learning and compare their performance. We study which datasets were commonly used and what comparison criteria were mostly adopted for software fault prediction. We select 68 primary studies from a wide list of initially selected set following our quality assessment criteria and present answers to our research questions.","Software fault prediction, Defect prediction, Machine learning techniques, Data mining techniques, Deep learning techniques, Performance measures",
