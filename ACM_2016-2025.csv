"Item type","Authors","Title","Journal","Publication year","Volume","Issue","Pages","Publisher","Address","Proceedings title","Conference location","Date published","ISBN","ISSN","URLs","DOI","Abstract","Keywords","Series"
"Conference Paper","Omri S,Sinz C","Deep Learning for Software Defect Prediction: A Survey","","2020","","","209–214","Association for Computing Machinery","New York, NY, USA","Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops","Seoul, Republic of Korea","2020","9781450379632","","https://doi.org/10.1145/3387940.3391463;http://dx.doi.org/10.1145/3387940.3391463","10.1145/3387940.3391463","Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.","software testing, software quality assurance, software defect prediction, machine learning, deep learning","ICSEW'20"
"Conference Paper","Ho A,Nhat Hai N,Thi-Mai-Anh B","Combining Deep Learning and Kernel PCA for Software Defect Prediction","","2022","","","360–367","Association for Computing Machinery","New York, NY, USA","Proceedings of the 11th International Symposium on Information and Communication Technology","Hanoi, Vietnam","2022","9781450397254","","https://doi.org/10.1145/3568562.3568587;http://dx.doi.org/10.1145/3568562.3568587","10.1145/3568562.3568587","Software defect prediction aims to automatically determine the most likely location of defective program elements (i.e., statement, method, class, module etc.). Previous studies for software defect prediction mainly focus on exploring designing features such as source code complexity, object oriented design metrics etc. to classify program elements into two categories: (i) defective and (ii) non-defective. Although these approaches have obtained promising results, there exists two significant challenges in this research field: (i) removing irrelevant and redundant information from designing structures ; (ii) reducing the impact of skewed data distribution on learning models. In this paper, we aim to address these two issues by firstly applying kernel PCA to extract essential information from designing features and secondly proposing a deep neural network model which investigates the non-linear relationship among features. In order to mitigate the class imbalance, we apply a weighted loss function combined with a bootstrapping method to handle batch training mechanism of our model. We conducted some experiments to assess the performance of our proposed approach over NASA (with 10 projects) and PROMISE (with 34 projects) datasets. In order to leverage the efficiency of kernel PCA technique in software defect prediction, we compared it to some traditional feature selection approaches over a high-dimensional dataset ECLIPSE. The empirical results showed that our proposed method has outperformed these other state-of-the-art models by effectively predicting defective source files.","kernel PCA, feature reduction, deep neural network","SoICT '22"
"Conference Paper","Tang F,He P","Software Defect Prediction using Multi-scale Structural Information","","2023","","","548–556","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence","Tianjin, China","2023","9781450399029","","https://doi.org/10.1145/3594315.3594371;http://dx.doi.org/10.1145/3594315.3594371","10.1145/3594315.3594371","In recent years, most researches have used the sequence of nodes in the abstract syntax tree (AST) of code to extract features for software defect prediction (SDP). While the AST is a kind of graph data, it may ignore some part of the structural information to use the original graph data as a sequence for input. Thus, Graph neural network (GNN) has been used to extract structural information in SDP. However, existing researches ignore that GNN learning is inherently local. It is difficult to interact between remote nodes and to capture long-term dependencies in source code. We apply a combination model of GNN Transformer to predict the software defects. Using an AST directly as the input, GNN extracts local features and structural information between the node and its neighbors. We then encode the relative and absolute positions of the nodes in the AST. The position encodings are passed into the Transformer along with the feature information extracted by GNN to extract the global features, which are the long-term dependencies between nodes. Finally, the extracted fused features are used in the SDP. Experiments on the PROMISE dataset have shown that our method achieves higher F-measure and better identification of defective features in source code than the state-of-the-art SDP method.","deep learning, Transformer, Software defect prediction, Graph neural network","ICCAI '23"
"Conference Paper","Qiu X,Fan P,Ren J","Convolutional Neural Network-Based Research on Software Engineering Defect Prediction","","2024","","","305–308","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th International Conference on Information Technologies and Electrical Engineering","Changde, Hunan, China","2024","","","https://doi.org/10.1145/3640115.3640164;http://dx.doi.org/10.1145/3640115.3640164","10.1145/3640115.3640164","Defect prediction plays a crucial role in software engineering by identifying potential issues before they manifest as costly problems. In this research, we focus on enhancing defect prediction techniques using Convolutional Neural Networks (CNNs). CNNs have demonstrated significant success in various domains, primarily image analysis, due to their ability to capture complex patterns and relationships within data. We propose a novel approach that leverages the power of CNNs to automatically learn and extract features from software engineering datasets, enabling improved defect prediction accuracy. Our experimental results showcase the effectiveness of the CNN-based technique in comparison to traditional methods. The proposed CNN model exhibits promising potential to advance defect prediction capabilities and contribute to the overall quality and reliability of software systems. This research opens up new avenues for applying deep learning techniques to software engineering challenges and paves the way for further exploration in this interdisciplinary field.","Convolutional Neural Network, Defect Analysis, Defect Prediction, Software Engineering, Software Quality","ICITEE '23"
"Conference Paper","Li Z,Pan M,Pei Y,Zhang T,Wang L,Li X","Robust Learning of Deep Predictive Models from Noisy and Imbalanced Software Engineering Datasets","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering","Rochester, MI, USA","2023","9781450394758","","https://doi.org/10.1145/3551349.3556941;http://dx.doi.org/10.1145/3551349.3556941","10.1145/3551349.3556941","With the rapid development of Deep Learning, deep predictive models have been widely applied to improve Software Engineering tasks, such as defect prediction and issue classification, and have achieved remarkable success. They are mostly trained in a supervised manner, which heavily relies on high-quality datasets. Unfortunately, due to the nature and source of software engineering data, the real-world datasets often suffer from the issues of sample mislabelling and class imbalance, thus undermining the effectiveness of deep predictive models in practice. This problem has become a major obstacle for deep learning-based Software Engineering. In this paper, we propose RobustTrainer, the first approach to learning deep predictive models on raw training datasets where the mislabelled samples and the imbalanced classes coexist. RobustTrainer consists of a two-stage training scheme, where the first learns feature representations robust to sample mislabelling and the second builds a classifier robust to class imbalance based on the learned representations in the first stage. We apply RobustTrainer to two popular Software Engineering tasks, i.e., Bug Report Classification and Software Defect Prediction. Evaluation results show that RobustTrainer effectively tackles the mislabelling and class imbalance issues and produces significantly better deep predictive models compared to the other six comparison approaches.","Deep Learning, Imbalanced Data, Mislabelling, Predictive Models","ASE '22"
"Conference Paper","Zeng Z,Zhang Y,Zhang H,Zhang L","Deep just-in-time defect prediction: how far are we?","","2021","","","427–438","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis","Virtual, Denmark","2021","9781450384599","","https://doi.org/10.1145/3460319.3464819;http://dx.doi.org/10.1145/3460319.3464819","10.1145/3460319.3464819","Defect prediction aims to automatically identify potential defective code with minimal human intervention and has been widely studied in the literature. Just-in-Time (JIT) defect prediction focuses on program changes rather than whole programs, and has been widely adopted in continuous testing. CC2Vec, state-of-the-art JIT defect prediction tool, first constructs a hierarchical attention network (HAN) to learn distributed vector representations of both code additions and deletions, and then concatenates them with two other embedding vectors representing commit messages and overall code changes extracted by the existing DeepJIT approach to train a model for predicting whether a given commit is defective. Although CC2Vec has been shown to be the state of the art for JIT defect prediction, it was only evaluated on a limited dataset and not compared with all representative baselines. Therefore, to further investigate the efficacy and limitations of CC2Vec, this paper performs an extensive study of CC2Vec on a large-scale dataset with over 310,370 changes (8.3 X larger than the original CC2Vec dataset). More specifically, we also empirically compare CC2Vec against DeepJIT and representative traditional JIT defect prediction techniques. The experimental results show that CC2Vec cannot consistently outperform DeepJIT, and neither of them can consistently outperform traditional JIT defect prediction. We also investigate the impact of individual traditional defect prediction features and find that the added-line-number feature outperforms other traditional features. Inspired by this finding, we construct a simplistic JIT defect prediction approach which simply adopts the added-line-number feature with the logistic regression classifier. Surprisingly, such a simplistic approach can outperform CC2Vec and DeepJIT in defect prediction, and can be 81k X/120k X faster in training/testing. Furthermore, the paper also provides various practical guidelines for advancing JIT defect prediction in the near future.","Software Defect Prediction, Just-In-Time Prediction, Deep Learning","ISSTA 2021"
"Conference Paper","Gesi J,Li J,Ahmed I","An Empirical Examination of the Impact of Bias on Just-in-time Defect Prediction","","2021","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)","Bari, Italy","2021","9781450386654","","https://doi.org/10.1145/3475716.3475791;http://dx.doi.org/10.1145/3475716.3475791","10.1145/3475716.3475791","Background: Just-In-Time (JIT) defect prediction models predict if a commit will introduce defects in the future. DeepJIT and CC2Vec are two state-of-the-art JIT Deep Learning (DL) techniques. Usually, defect prediction techniques are evaluated, treating all training data equally. However, data is usually imbalanced not only in terms of the overall class label (e.g., defect and non-defect) but also in terms of characteristics such as File Count, Edit Count, Multiline Comments, Inward Dependency Sum etc. Prior research has investigated the impact of class imbalance on prediction technique's performance but not the impact of imbalance of other characteristics. Aims: We aim to explore the impact of different commit related characteristic's imbalance on DL defect prediction. Method: We investigated different characteristic's impact on the overall performance of DeepJIT and CC2Vec. We also propose a Siamese network based few-shot learning framework for JIT defect prediction (SifterJIT) combining Siamese network and DeepJIT. Results: Our results show that DeepJIT and CC2Vec lose out on the performance by around 20% when trained and tested on imbalanced data. However, SifterJIT can outperform state-of-the-art DL techniques with an average of 8.65% AUC score, 11% precision, and 6% F1-score improvement. Conclusions: Our results highlight that dataset imbalanced in terms of commit characteristics can significantly impact prediction performance, and few-shot learning based techniques can help alleviate the situation.","software engineering, few-shot learning, defect prediction, Deep learning","ESEM '21"
"Conference Paper","Keshavarz H,Nagappan M","ApacheJIT: a large dataset for just-in-time defect prediction","","2022","","","191–195","Association for Computing Machinery","New York, NY, USA","Proceedings of the 19th International Conference on Mining Software Repositories","Pittsburgh, Pennsylvania","2022","9781450393034","","https://doi.org/10.1145/3524842.3527996;http://dx.doi.org/10.1145/3524842.3527996","10.1145/3524842.3527996","In this paper, we present ApacheJIT, a large dataset for Just-In-Time (JIT) defect prediction. ApacheJIT consists of clean and bug-inducing software changes in 14 popular Apache projects. ApacheJIT has a total of 106,674 commits (28,239 bug-inducing and 78,435 clean commits). Having a large number of commits makes ApacheJIT a suitable dataset for machine learning JIT models, especially deep learning models that require large training sets to effectively generalize the patterns present in the historical data to future data.","software engineering, defect prediction, dataset","MSR '22"
"Conference Paper","Chen J,Hu K,Yu Y,Chen Z,Xuan Q,Liu Y,Filkov V","Software visualization and deep transfer learning for effective software defect prediction","","2020","","","578–589","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering","Seoul, South Korea","2020","9781450371216","","https://doi.org/10.1145/3377811.3380389;http://dx.doi.org/10.1145/3377811.3380389","10.1145/3377811.3380389","Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.","cross-project defect prediction, deep transfer learning, self-attention, software visualization, within-project defect prediction","ICSE '20"
"Conference Paper","Fan M,Jia A,Liu J,Liu T,Chen W","When representation learning meets software analysis","","2020","","","17–18","Association for Computing Machinery","New York, NY, USA","Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages","Virtual, USA","2020","9781450381253","","https://doi.org/10.1145/3416506.3423578;http://dx.doi.org/10.1145/3416506.3423578","10.1145/3416506.3423578","In recent years, deep learning is increasingly prevalent in the field of Software Engineering (SE). Especially, representation learning, which can learn vectors from the syntactic and semantics of the code, offers much convenience and promotion for the downstream tasks such as code search and vulnerability detection. In this work, we introduce our two applications of leveraging representation learning for software analysis, including defect prediction and vulnerability detection.","vulnerability detection, representation learning, defect prediction","RL+SE&PL 2020"
"Conference Paper","Hu B,Wu Y,Peng X,Sha C,Wang X,Fu B,Zhao W","Predicting change propagation between code clone instances by graph-based deep learning","","2022","","","425–436","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension","Virtual Event","2022","9781450392983","","https://doi.org/10.1145/3524610.3527912;http://dx.doi.org/10.1145/3524610.3527912","10.1145/3524610.3527912","Code clones widely exist in open-source and industrial software projects and are still recognized as a threat to software maintenance due to the additional effort required for the simultaneous maintenance of multiple clone instances and potential defects caused by inconsistent changes in clone instances. To alleviate the threat, it is essential to accurately and efficiently make the decisions of change propagation between clone instances. Based on an exploratory study on clone change propagation with five famous open-source projects, we find that a clone class can have both propagation-required changes and propagation-free changes and thus fine-grained change propagation decision is required. Based on the findings, we propose a graph-based deep learning approach to predict the change propagation requirements of clone instances. We develop a graph representation, named Fused Clone Program Dependency Graph (FC-PDG), to capture the textual and structural code contexts of a pair of clone instances along with the changes on one of them. Based on the representation, we design a deep learning model that uses a Relational Graph Convolutional Network (R-GCN) to predict the change propagation requirement. We evaluate the approach with a dataset constructed based on 51 open-source Java projects, which includes 24,672 pairs of matched changes and 38,041 non-matched changes. The results show that the approach achieves high precision (83.1%), recall (81.2%), and F1-score (82.1%). Our further evaluation with three other open-source projects confirms the generality of the trained clone change propagation prediction model.","","ICPC '22"
"Conference Paper","Ferreira F,Silva LL,Valente MT","Software engineering meets deep learning: a mapping study","","2021","","","1542–1549","Association for Computing Machinery","New York, NY, USA","Proceedings of the 36th Annual ACM Symposium on Applied Computing","Virtual Event, Republic of Korea","2021","9781450381048","","https://doi.org/10.1145/3412841.3442029;http://dx.doi.org/10.1145/3412841.3442029","10.1145/3412841.3442029","Deep Learning (DL) is being used nowadays in many traditional Software Engineering (SE) problems and tasks. However, since the renaissance of DL techniques is still very recent, we lack works that summarize and condense the most recent and relevant research conducted at the intersection of DL and SE. Therefore, in this paper, we describe the first results of a mapping study covering 81 papers about DL & SE. Our results confirm that DL is gaining momentum among SE researchers over the years and that the top-3 research problems tackled by the analyzed papers are documentation, defect prediction, and testing.","deep learning, software engineering","SAC '21"
"Conference Paper","Nguyen AT,Le TH,Babar MA","Automated Code-centric Software Vulnerability Assessment: How Far Are We? An Empirical Study in C/C++","","2024","","","72–83","Association for Computing Machinery","New York, NY, USA","Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement","Barcelona, Spain","2024","","","https://doi.org/10.1145/3674805.3686670;http://dx.doi.org/10.1145/3674805.3686670","10.1145/3674805.3686670","Background: The C/C++ languages hold significant importance in Software Engineering research because of their widespread use in practice. Numerous studies have utilized Machine Learning (ML) and Deep Learning (DL) techniques to detect software vulnerabilities (SVs) in the source code written in these languages. However, the application of these techniques in function-level SV assessment has been largely unexplored. SV assessment is increasingly crucial as it provides detailed information on the exploitability, impacts, and severity of security defects, thereby aiding in their prioritization and remediation. Aims: We conduct the first empirical study to investigate and compare the performance of ML and DL models, many of which have been used for SV detection, for function-level SV assessment in C/C++. Method: Using 9,993 vulnerable C/C++ functions, we evaluated the performance of six multi-class ML models and five multi-class DL models for the SV assessment at the function level based on the Common Vulnerability Scoring System (CVSS). We further explore multi-task learning, which can leverage common vulnerable code to predict all SV assessment outputs simultaneously in a single model, and compare the effectiveness and efficiency of this model type with those of the original multi-class models. Results: We show that ML has matching or even better performance compared to the multi-class DL models for function-level SV assessment with significantly less training time. Employing multi-task learning allows the DL models to perform significantly better, with an average of 8–22% increase in Matthews Correlation Coefficient (MCC), than the multi-class models. Conclusions: We distill the practices of using data-driven techniques for function-level SV assessment in C/C++, including the use of multi-task DL to balance efficiency and effectiveness. This can establish a strong foundation for future work in this area.","Deep Learning, Machine Learning, Mining Software Repositories, Security Vulnerability, Vulnerability Assessment","ESEM '24"
"Journal Article","Ding Z,Li H,Shang W,Chen TH","Towards Learning Generalizable Code Embeddings Using Task-agnostic Graph Convolutional Networks","ACM Trans. Softw. Eng. Methodol.","2023","32","2","","Association for Computing Machinery","New York, NY, USA","","","2023-03","","1049-331X","https://doi.org/10.1145/3542944;http://dx.doi.org/10.1145/3542944","10.1145/3542944","Code embeddings have seen increasing applications in software engineering (SE) research and practice recently. Despite the advances in embedding techniques applied in SE research, one of the main challenges is their generalizability. A recent study finds that code embeddings may not be readily leveraged for the downstream tasks that the embeddings are not particularly trained for. Therefore, in this article, we propose GraphCodeVec, which represents the source code as graphs and leverages the Graph Convolutional Networks to learn more generalizable code embeddings in a task-agnostic manner. The edges in the graph representation are automatically constructed from the paths in the abstract syntax trees, and the nodes from the tokens in the source code. To evaluate the effectiveness of GraphCodeVec , we consider three downstream benchmark tasks (i.e., code comment generation, code authorship identification, and code clones detection) that are used in a prior benchmarking of code embeddings and add three new downstream tasks (i.e., source code classification, logging statements prediction, and software defect prediction), resulting in a total of six downstream tasks that are considered in our evaluation. For each downstream task, we apply the embeddings learned by GraphCodeVec and the embeddings learned from four baseline approaches and compare their respective performance. We find that GraphCodeVec outperforms all the baselines in five out of the six downstream tasks, and its performance is relatively stable across different tasks and datasets. In addition, we perform ablation experiments to understand the impacts of the training context (i.e., the graph context extracted from the abstract syntax trees) and the training model (i.e., the Graph Convolutional Networks) on the effectiveness of the generated embeddings. The results show that both the graph context and the Graph Convolutional Networks can benefit GraphCodeVec in producing high-quality embeddings for the downstream tasks, while the improvement by Graph Convolutional Networks is more robust across different downstream tasks and datasets. Our findings suggest that future research and practice may consider using graph-based deep learning methods to capture the structural information of the source code for SE tasks.","neural network, code embeddings, source code representation, Machine learning",""
"Journal Article","Zhang H,Fu Z,Li G,Ma L,Zhao Z,Yang H,Sun Y,Liu Y,Jin Z","Towards Robustness of Deep Program Processing Models—Detection, Estimation, and Enhancement","ACM Trans. Softw. Eng. Methodol.","2022","31","3","","Association for Computing Machinery","New York, NY, USA","","","2022-04","","1049-331X","https://doi.org/10.1145/3511887;http://dx.doi.org/10.1145/3511887","10.1145/3511887","Deep learning (DL) has recently been widely applied to diverse source code processing tasks in the software engineering (SE) community, which achieves competitive performance (e.g., accuracy). However, the robustness, which requires the model to produce consistent decisions given minorly perturbed code inputs, still lacks systematic investigation as an important quality indicator. This article initiates an early step and proposes a framework CARROT for robustness detection, measurement, and enhancement of DL models for source code processing. We first propose an optimization-based attack technique CARROTA to generate valid adversarial source code examples effectively and efficiently. Based on this, we define the robustness metrics and propose robustness measurement toolkit CARROTM, which employs the worst-case performance approximation under the allowable perturbations. We further propose to improve the robustness of the DL models by adversarial training (CARROTT) with our proposed attack techniques. Our in-depth evaluations on three source code processing tasks (i.e., functionality classification, code clone detection, defect prediction) containing more than 3 million lines of code and the classic or SOTA DL models, including GRU, LSTM, ASTNN, LSCNN, TBCNN, CodeBERT, and CDLH, demonstrate the usefulness of our techniques for ❶ effective and efficient adversarial example detection, ❷ tight robustness estimation, and ❸ effective robustness enhancement.","robustness enhancement, adversarial attack, big code, Source code processing",""
"Conference Paper","Hoang T,Dam HK,Kamei Y,Lo D,Ubayashi N","DeepJIT: an end-to-end deep learning framework for just-in-time defect prediction","","2019","","","34–45","IEEE Press","Montreal, Quebec, Canada","Proceedings of the 16th International Conference on Mining Software Repositories","","2019","","","https://doi.org/10.1109/MSR.2019.00016;http://dx.doi.org/10.1109/MSR.2019.00016","10.1109/MSR.2019.00016","Software quality assurance efforts often focus on identifying defective code. To find likely defective code early, change-level defect prediction - aka. Just-In-Time (JIT) defect prediction - has been proposed. JIT defect prediction models identify likely defective changes and they are trained using machine learning techniques with the assumption that historical changes are similar to future ones. Most existing JIT defect prediction approaches make use of manually engineered features. Unlike those approaches, in this paper, we propose an end-to-end deep learning framework, named DeepJIT, that automatically extracts features from commit messages and code changes and use them to identify defects. Experiments on two popular software projects (i.e., QT and OPENSTACK) on three evaluation settings (i.e., cross-validation, short-period, and long-period) show that the best variant of DeepJIT (DeepJIT-Combined), compared with the best performing state-of-the-art approach, achieves improvements of 10.36--11.02% for the project QT and 9.51--13.69% for the project OPENSTACK in terms of the Area Under the Curve (AUC).","","MSR '19"
"Conference Paper","Lyu MR","AI Techniques in Software Engineering Paradigm","","2018","","","2","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering","Berlin, Germany","2018","9781450350952","","https://doi.org/10.1145/3184407.3184440;http://dx.doi.org/10.1145/3184407.3184440","10.1145/3184407.3184440","In the next decade, Artificial Intelligent (AI) techniques can see wide adoption in our daily life to release human burden. In our recent Software Engineering research, we investigated on the design of novel AI methods to facilitate all three major phases in software engineering: development, operation, and analysis. In this talk, I will first introduce the AI techniques we employed, including machine learning framework, classification, clustering, matrix factorization, topic modeling, deep learning, and parallel computing platform. Then I will explain the challenges in each phase and describe our recently proposed methodologies. First in development phase, we suggested an automated code completion technique via deep learning. Our technique learns the code style from lots of existing code bases, and recommends the most suitable token based on the trained deep learning model and current coding context. Besides, to help developers in conducting effective logging, we designed a tool named LogAdvisor, which tells developers whether they should write a logging statement in the current code block or not. Secondly, in operation phase, we implemented a continuous and passive authentication method for mobile phones based on user touch biometrics. Different from the traditional password authentication scheme, our method can recognize malicious attackers based on abnormal user behaviors. Moreover, we developed PAID, which automatically prioritizes app issues by mining user reviews. Finally, in analysis phase, we designed systematic data analytics techniques for software reliability prediction. Besides, to make full use of the crucial runtime information, we proposed effective methods for every step in log analysis, including log parsing, feature extraction, and log mining. Furthermore, we developed a CNN-based defect prediction method to help developers find the buggy code. In the end, we expect to establish a comprehensive framework for systematic employment of AI techniques in the Software Engineering paradigm.","software engineering, artificial intelligence","ICPE '18"
"Conference Paper","Dam HK,Pham T,Ng SW,Tran T,Grundy J,Ghose A,Kim T,Kim CJ","Lessons learned from using a deep tree-based model for software defect prediction in practice","","2019","","","46–57","IEEE Press","Montreal, Quebec, Canada","Proceedings of the 16th International Conference on Mining Software Repositories","","2019","","","https://doi.org/10.1109/MSR.2019.00017;http://dx.doi.org/10.1109/MSR.2019.00017","10.1109/MSR.2019.00017","Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source projects contributed by our industry partner Samsung and the other from the public PROMISE repository.","defect prediction, deep learning","MSR '19"
"Conference Paper","Wang S,Liu T,Tan L","Automatically learning semantic features for defect prediction","","2016","","","297–308","Association for Computing Machinery","New York, NY, USA","Proceedings of the 38th International Conference on Software Engineering","Austin, Texas","2016","9781450339001","","https://doi.org/10.1145/2884781.2884804;http://dx.doi.org/10.1145/2884781.2884804","10.1145/2884781.2884804","Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models.To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs).Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision, 11.5% in recall, and 14.2% in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1.","","ICSE '16"
"Conference Paper","Ibrahim RF,Qusef A","Software Bug Count Prediction Using Abstract Syntax Trees (ASTs)","","2025","","","39–45","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2024 13th International Conference on Software and Information Engineering","","2025","","","https://doi.org/10.1145/3708635.3708652;http://dx.doi.org/10.1145/3708635.3708652","10.1145/3708635.3708652","Predicting software defects is important for ensuring high-quality software delivery. This proposed study investigates the effectiveness of deep learning models in predicting software bug counts compared to traditional machine learning models. We concentrated our investigation on two fundamental questions: (1) Can deep learning techniques surpass traditional machine learning approaches in accurately predicting bug counts in software modules via regression analysis? (2) In the context of regression-based bug count prediction, does a deep learning model that leverages features extracted from Abstract Syntax Trees (ASTs) demonstrate superior performance compared to one that relies on Object-Oriented (OO) metrics? To address RQ-1, we trained layered Long Short-Term Memory (LSTM) networks and Convolutional Neural Networks (CNNs) on (17) OO metrics from the PROMISE and SPSC datasets and compared their performance. For RQ-2, we extracted relevant features from ASTs using specific node types and combined them with the OO metrics to train the LSTM and CNN models. Four experiments were conducted: LSTM on OO metrics, LSTM on AST features, CNN on OO metrics, and CNN on AST features. Evaluation using Mean Absolute Error (MAE) and Mean Relative Error (MRE) showed that deep learning models outperformed traditional machine learning models, with layered LSTM and CNN models trained on combined OO metrics and AST features achieving the best defect predictive accuracy. These findings highlight the potential of deep learning approaches in software defect prediction and show the importance of feature selection in achieving optimal results.","Bug Prediction, Abstract Syntax Tree (AST), LSTM, Object-Oriented (OO) Matrices.","ICSIE '24"
"Journal Article","Bal PR,Kumar S","Cross Project Defect Prediction using Dropout Regularized Deep Learning and Unique Matched Metrics","ACM Trans. Manage. Inf. Syst.","2025","16","3","","Association for Computing Machinery","New York, NY, USA","","","2025-05","","2158-656X","https://doi.org/10.1145/3698109;http://dx.doi.org/10.1145/3698109","10.1145/3698109","The primary goal of software defect prediction (SDP) is to predict the software defects for a specific software using historical data or data from past releases of software projects. The existing state of arts on SDP primarily discusses two prediction scenarios: Within-project Defect Prediction (WPDP) and Cross-project Defect Prediction (CPDP). The prediction model belongs to the WPDP scenario, which means that the model is trained and tested on different parts of the same dataset or trained on the dataset belonging to the previous version of the same project. While in the CPDP scenario, training and testing occur on different software project datasets. Due to the unavailability of historical datasets or prior releases of software defect datasets, CPDP is more useful in real-life scenarios. So, CPDP analysis is a very challenging issue in the SDP domain. Sometimes, machine learning (ML) models perform poorly due to inadequate training in the CPDP scenario. To support better CPDP performance, we must carefully build an ML model focusing on lower training error and overfitting issues. To address these issues, we have proposed a cross-project data preprocessing method to correlate the metrics of different project datasets, namely, Unique Selection of Matched Metrics (USMM), using the KS test and Hungarian method. To further improve the CPDP performance, we have also used the dropout regularized deep learning (DRDL) model. We have deployed 34 software defect datasets to validate the DRDL model and USMM method. The experimental results demonstrate that the DRDL model using the USMM method (DRDL-USMM) is a promising model to enhance the prediction accuracy, and an improvement in the range of 3.3% to 8.5% as compared to the existing works in the CPDP scenario has been found.","Deep learning, cross project defect prediction, correlated matched metrics, dropout regularization",""
"Journal Article","Ye J,Li Z,Tang X,Zou D,Xu S,Qiang W,Jin H","A Causal Learning Framework for Enhancing Robustness of Source Code Models","Proc. ACM Softw. Eng.","2025","2","FSE","","Association for Computing Machinery","New York, NY, USA","","","2025-06","","","https://doi.org/10.1145/3729387;http://dx.doi.org/10.1145/3729387","10.1145/3729387","Deep Learning (DL) models are useful for many software engineering tasks. However, these models are susceptible to adversarial attacks, partly because they learn spurious features that incur spurious correlations between these features and model predictions. In this paper, we tackle the problem with a novel causal learning framework, dubbed CausalCode, which leverages causal inference principles to mitigate spurious correlations. At a high level, CausalCode can be characterized as follows: (i) it uses causal data augmentation to generate intervention examples to disrupt spurious correlations; (ii) it leverages regularization to learn invariant representations that prefer causal features to spurious features; (iii) it can enhance the robustness of multiple DL models for source code-based software engineering tasks because it is task-agnostic and model-agnostic. To evaluate its effectiveness, we conduct comprehensive experiments on two models (i.e., CodeBERT and GraphCodeBERT), with respect to four software engineering tasks (i.e., defect detection, functionality classification, code translation, and code repair). Experimental results show that CausalCode outperforms the state-of-the-art approaches in enhancing the robustness of these models.","Adversarial Robustness, Causal Learning, Code Models",""
